# Layer Prediction L3->L6 - Full Training (1000 batches)

model:
  name: "EleutherAI/pythia-410m"
  device: "cuda"

dataset:
  name: "monology/pile-uncopyrighted"
  split: "train"
  max_length: 128

layer_prediction:
  input_layer: 3
  target_layer: 6
  comb_seq_n: 16
  model_type: "Bilinear"
  optimizer_type: "Muon"
  batch_size: 32
  learning_rate: 0.02
  hidden_multiplier: 4
  bias: true
  debug: false
  n_batches: 20
  n_batches_full: 50
