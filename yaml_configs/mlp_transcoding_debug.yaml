# MLP Transcoding - Debug Mode (20 batches)

model:
  name: "EleutherAI/pythia-410m"
  device: "cuda"

dataset:
  name: "monology/pile-uncopyrighted"
  split: "train"
  max_length: 128

transcoding:
  layer_idx: 3
  model_type: "MLP"
  optimizer_type: "Muon"
  batch_size: 512
  learning_rate: 0.02
  hidden_multiplier: 4
  bias: true
  debug: true
  n_batches: 20
  n_batches_full: 1000
